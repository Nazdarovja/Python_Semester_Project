{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import math,random\n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "import pprint\n",
    "\n",
    "import pandas as pd\n",
    "from src.features.build_features import word_count_series\n",
    "from src.features.text_blob_analysis import analyze_sentiment\n",
    "from src.data.make_dataset import create_dataset\n",
    "from src.data.util import unzip_file\n",
    "\n",
    "def step_function(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "\n",
    "def perceptron_output(weights, bias, x):\n",
    "    '''Returns 1 if the perceptrion 'fires', 0 if not '''\n",
    "    return step_function(np.dot(weights, x) + bias)\n",
    "\n",
    "def sigmoid(t):\n",
    "    return 1 / (1 + math.exp(-t))\n",
    "\n",
    "def neuron_output(weights, inputs):\n",
    "    return sigmoid(np.dot(weights, inputs))\n",
    "\n",
    "def predict(input, network):\n",
    "    return feed_forward(network, input)[-1]\n",
    "\n",
    "def feed_forward(neural_network, input_vector):\n",
    "    \"\"\"takes in a neural network (represented as a list of lists of lists of weights)\n",
    "    and returns the output from forward-propagating the input\"\"\"\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    for layer in neural_network:\n",
    "\n",
    "        input_with_bias = input_vector + [1]             # add a bias input\n",
    "        output = [neuron_output(neuron, input_with_bias) # compute the output\n",
    "                  for neuron in layer]                   # for this layer\n",
    "        outputs.append(output)                           # and remember it\n",
    "\n",
    "        # the input to the next layer is the output of this one\n",
    "        input_vector = output\n",
    "\n",
    "    return outputs\n",
    "    \n",
    "def backpropagate(network, input_vector, targets):\n",
    "    hidden_outputs, outputs = feed_forward(network, input_vector)\n",
    "    \n",
    "  \n",
    "    # the output * (1 - output) is from the derivative of sigmoid\n",
    "    output_deltas = [output * (1 - output) * (output - target) for output, target in zip(outputs, targets)]\n",
    "        # adjust weights for output layer, one neuron at a time\n",
    "    for i, output_neuron in enumerate(network[-1]):\n",
    "    # focus on the ith output layer neuron\n",
    "        for j, hidden_output in enumerate(hidden_outputs + [1]):\n",
    "            # adjust the jth weight based on both\n",
    "            # this neuron's delta and its jth input\n",
    "            output_neuron[j] -= output_deltas[i] * hidden_output\n",
    "    # back-propagate errors to hidden layer\n",
    "    hidden_deltas = [hidden_output * (1 - hidden_output) * np.dot(output_deltas, [n[i] for n in output_layer])for i, hidden_output in enumerate(hidden_outputs)]\n",
    "        \n",
    "    # adjust weights for hidden layer, one neuron at a time\n",
    "    for i, hidden_neuron in enumerate(network[0]):\n",
    "        for j, input in enumerate(input_vector + [1]):\n",
    "            hidden_neuron[j] -= hidden_deltas[i] * input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating missing paths...\n",
      "Skipping unzip...\n",
      "Skipping data filtering...\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "# Importing data\n",
    "training_df, df = create_dataset()\n",
    "\n",
    "print(len(df))\n",
    "#print(len(testdata_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing sentiment...: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 750/750 [00:00<00:00, 771.16it/s]\n",
      "Analyzing sentiment...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 750/750 [00:00<00:00, 369563.91it/s]\n",
      "Analyzing sentiment...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 750/750 [00:00<00:00, 375878.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[135, -0.05, 0.25227272727272726], [367, 0.2929487179487179, 0.6051282051282051], [174, 0.2529004329004329, 0.4183982683982685], [162, -0.04561965811965812, 0.4529914529914531], [264, -0.1270408163265306, 0.464030612244898], [219, 0.3233918128654971, 0.6573099415204676], [287, -0.07853535353535353, 0.311489898989899], [175, -0.28333333333333327, 0.6733333333333333], [301, -0.020205026455026462, 0.5448412698412698], [223, 0.35684523809523805, 0.544047619047619]]\n"
     ]
    }
   ],
   "source": [
    "# targets\n",
    "series = df['genre'].value_counts()\n",
    "genre_labels = series.keys() # getting genre labels\n",
    "targets = [[1 if i == j else 0 for i in genre_labels] for j in df['genre']]\n",
    "# features\n",
    "features_series = word_count_series(df['lyrics'])\n",
    "df = analyze_sentiment(df)\n",
    "polarity = df['polarity']\n",
    "subjectivity = df['subjectivity']\n",
    "\n",
    "inputs = [[f, p, s]  for f,p,s in zip(features_series, polarity, subjectivity)]\n",
    "print(inputs[0:10])\n",
    "\n",
    "#shuffle(inputs)\n",
    "#inputs = inputs[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.8444218515250481, 0.7579544029403025, 0.420571580830845, 0.25891675029296335]], [[0.5112747213686085, 0.4049341374504143], [0.7837985890347726, 0.30331272607892745], [0.4765969541523558, 0.5833820394550312]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████▋                                                                                       | 998/10000 [00:37<05:41, 26.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.8444218515250481, 0.7579544029403025, 0.420571580830845, 0.25891675029296335]], [[1.6984514608495225, 1.5921108769317691], [-1.4146082091810208, -1.8950940721377507], [-1.9082127145963963, -1.801427629294161]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████▏                                                                            | 1997/10000 [01:15<05:08, 25.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.8444218515250481, 0.7579544029403025, 0.420571580830845, 0.25891675029296335]], [[1.6984514608493004, 1.5921108769319912], [-1.4146082091805767, -1.8950940721381948], [-1.9082127145961743, -1.801427629294383]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████████▍                                                         | 3999/10000 [02:32<03:50, 25.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.8444218515250481, 0.7579544029403025, 0.420571580830845, 0.25891675029296335]], [[1.6984514608488563, 1.5921108769324352], [-1.4146082091796885, -1.895094072139083], [-1.9082127145957302, -1.801427629294827]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████████████▌                                      | 5997/10000 [03:48<02:28, 26.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.8444218515250481, 0.7579544029403025, 0.420571580830845, 0.25891675029296335]], [[1.6984514608484123, 1.5921108769328793], [-1.4146082091788004, -1.8950940721399712], [-1.908212714595286, -1.8014276292952711]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████████████████▊                   | 7999/10000 [05:03<01:15, 26.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.8444218515250481, 0.7579544029403025, 0.420571580830845, 0.25891675029296335]], [[1.6984514608479682, 1.5921108769333234], [-1.4146082091779122, -1.8950940721408593], [-1.908212714594842, -1.8014276292957152]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [06:18<00:00, 26.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.8444218515250481, 0.7579544029403025, 0.420571580830845, 0.25891675029296335]], [[1.6984514608475239, 1.5921108769337677], [-1.4146082091770236, -1.895094072141748], [-1.9082127145943977, -1.8014276292961595]]]\n"
     ]
    }
   ],
   "source": [
    "########### Træning af model ###########\n",
    "\n",
    "###########\n",
    "# Opsætning af Neural Network\n",
    "###########\n",
    "random.seed(0) # to get repeatable results\n",
    "input_size = 3 # antal af input noder (samme antal som feautures)\n",
    "num_hidden = 1 # antal af hidden noder\n",
    "output_size = 3 # antal af output noder (i vores tilfælde, genres)\n",
    "\n",
    "# each hidden neuron has one weight per input, plus a bias weight\n",
    "hidden_layer = [[random.random() for __ in range(input_size + 1)] for __ in range(num_hidden)]\n",
    "\n",
    "# each output neuron has one weight per hidden neuron, plus a bias weight\n",
    "output_layer = [[random.random() for __ in range(num_hidden + 1)] for __ in range(output_size)]\n",
    "\n",
    "# the network starts out with random weights\n",
    "network = [hidden_layer, output_layer]\n",
    "\n",
    "# Iteration of training\n",
    "num = 0\n",
    "print(network)\n",
    "for __ in  tqdm(range(10000)):\n",
    "    num = num +1\n",
    "    if num == 1000 or num == 2000 or num == 4000 or num == 6000 or num == 8000:\n",
    "        print(network)\n",
    "    for input_vector, target_vector in zip(inputs, targets):\n",
    "        backpropagate(network, input_vector, target_vector)\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.09597883597883598, 0.28423280423280417], [-0.009999999999999988, 0.3516666666666667], [0.06, 0.62], [0.15690359477124188, 0.3385620915032678], [0.07628855519480511, 0.6662822420634921], [0.19627450980392155, 0.6133333333333333], [-0.1220959595959596, 0.33181818181818185], [0.047708333333333346, 0.4533333333333333], [0.2197425381635908, 0.5253645477329689], [0.03166666666666666, 0.5516666666666666]]\n",
      "##########################\n",
      "Index(['Rock', 'Hip-Hop', 'Pop'], dtype='object')\n",
      "[0.899601214060026, 0.015641430721431964, 0.14530625652855883]\n"
     ]
    }
   ],
   "source": [
    "# 'Rock', 'Pop', 'Hip-Hop', 'Not Available', 'Metal', 'Country', 'Jazz', 'Electronic', 'Other', 'R&B', 'Indie', 'Folk'\n",
    "print(inputs[-10:])\n",
    "\n",
    "print('##########################')\n",
    "print(genre_labels)\n",
    "res = predict([1, 0], network)\n",
    "print(res)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
