{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import math,random\n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "import pprint\n",
    "\n",
    "import pandas as pd\n",
    "from src.features.build_features import word_count, sentence_avg_word_length, normalize\n",
    "from src.features.text_blob_analysis import analyze_sentiment, analyze_word_class\n",
    "from src.data.make_dataset import create_dataset\n",
    "from src.data.util import unzip_file\n",
    "\n",
    "def step_function(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "\n",
    "def perceptron_output(weights, bias, x):\n",
    "    '''Returns 1 if the perceptrion 'fires', 0 if not '''\n",
    "    return step_function(np.dot(weights, x) + bias)\n",
    "\n",
    "def sigmoid(t):\n",
    "    return 1 / (1 + math.exp(-t))\n",
    "\n",
    "def neuron_output(weights, inputs):\n",
    "    return sigmoid(np.dot(weights, inputs))\n",
    "\n",
    "def predict(input, network):\n",
    "    return feed_forward(network, input)[-1]\n",
    "\n",
    "def feed_forward(neural_network, input_vector):\n",
    "    \"\"\"takes in a neural network (represented as a list of lists of lists of weights)\n",
    "    and returns the output from forward-propagating the input\"\"\"\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    for layer in neural_network:\n",
    "\n",
    "        input_with_bias = input_vector + [1]             # add a bias input\n",
    "        output = [neuron_output(neuron, input_with_bias) # compute the output\n",
    "                  for neuron in layer]                   # for this layer\n",
    "        outputs.append(output)                           # and remember it\n",
    "\n",
    "        # the input to the next layer is the output of this one\n",
    "        input_vector = output\n",
    "\n",
    "    return outputs\n",
    "    \n",
    "def backpropagate(network, input_vector, targets):\n",
    "    hidden_outputs, outputs = feed_forward(network, input_vector)\n",
    "    \n",
    "  \n",
    "    # the output * (1 - output) is from the derivative of sigmoid\n",
    "    output_deltas = [output * (1 - output) * (output - target) for output, target in zip(outputs, targets)]\n",
    "        # adjust weights for output layer, one neuron at a time\n",
    "    for i, output_neuron in enumerate(network[-1]):\n",
    "    # focus on the ith output layer neuron\n",
    "        for j, hidden_output in enumerate(hidden_outputs + [1]):\n",
    "            # adjust the jth weight based on both\n",
    "            # this neuron's delta and its jth input\n",
    "            output_neuron[j] -= output_deltas[i] * hidden_output\n",
    "    # back-propagate errors to hidden layer\n",
    "    hidden_deltas = [hidden_output * (1 - hidden_output) * np.dot(output_deltas, [n[i] for n in output_layer])for i, hidden_output in enumerate(hidden_outputs)]\n",
    "        \n",
    "    # adjust weights for hidden layer, one neuron at a time\n",
    "    for i, hidden_neuron in enumerate(network[0]):\n",
    "        for j, input in enumerate(input_vector + [1]):\n",
    "            hidden_neuron[j] -= hidden_deltas[i] * input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating missing paths...\n",
      "Skipping unzip...\n",
      "Skipping data filtering...\n",
      "750\n",
      "       genre                                             lyrics\n",
      "745     Rock  back to back worlds apart in this endless figh...\n",
      "746     Rock  here i am caught in the moment seems to be fro...\n",
      "747      Pop  kiss me deep in the devil's rain when i'm danc...\n",
      "748  Hip-Hop  vocabulary spills remix consequence's verse yo...\n",
      "749  Hip-Hop  huh i couldn't be nobody but myself you know t...\n"
     ]
    }
   ],
   "source": [
    "# Importing data\n",
    "test_df, df = create_dataset()\n",
    "#test_df, df = create_dataset()\n",
    "\n",
    "print(len(df))\n",
    "#print(len(testdata_df))\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing sentiment...: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 750/750 [00:01<00:00, 743.33it/s]\n",
      "Analyzing sentiment...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 750/750 [00:00<00:00, 375878.60it/s]\n",
      "Analyzing sentiment...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 750/750 [00:00<00:00, 375654.17it/s]\n",
      "Preparing Text class analysis...: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 750/750 [00:10<00:00, 70.21it/s]\n",
      "Analyzing classes...: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 750/750 [00:00<00:00, 53712.53it/s]\n",
      "Analyzing classes...: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 750/750 [00:00<00:00, 55059.74it/s]\n",
      "Analyzing classes...: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 750/750 [00:00<00:00, 46998.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3838582677165354, 0.20958994708994708, 0.39804894179894174, 0.52], [0.25688976377952755, 0.08583333333333332, 0.7641666666666667, 0.31], [0.3828740157480315, 0.2467171717171717, 0.6143939393939394, 0.96], [0.7933070866141733, 0.09164887966971305, 0.4731040564373897, 1.42], [0.3828740157480315, 0.3010714285714285, 0.5139285714285714, 0.55], [0.6909448818897638, -0.02892581274934217, 0.44462481962481976, 1.32], [0.10826771653543307, 0.009523809523809518, 0.4385361552028219, 0.19], [0.1968503937007874, -0.06499999999999999, 0.4149999999999999, 0.18], [0.2529527559055118, 0.03792249417249417, 0.3697698135198135, 0.56], [0.1279527559055118, -0.015625000000000007, 0.40625, 0.31]]\n"
     ]
    }
   ],
   "source": [
    "# targets\n",
    "series = df['genre'].value_counts()\n",
    "genre_labels = series.keys() # getting genre labels\n",
    "targets = [[1 if i == j else 0 for i in genre_labels] for j in df['genre']]\n",
    "\n",
    "# features\n",
    "df = sentence_avg_word_length(df,\"avg_word_len\", 'lyrics')\n",
    "df = word_count(df,\"word_count\", 'lyrics')\n",
    "df = normalize(df, 'word_count_nm', 'word_count')\n",
    "df = analyze_sentiment(df)\n",
    "df = analyze_word_class(df)\n",
    "\n",
    "polarity = df['polarity']\n",
    "subjectivity = df['subjectivity']\n",
    "nouns = df['nouns']\n",
    "adverbs = df['adverbs']\n",
    "verbs = df['verbs']\n",
    "\n",
    "# Create feature list\n",
    "inputs = [[f, p, s, n] for f, p, s, n in zip(df[\"word_count_nm\"], polarity, subjectivity, nouns)]\n",
    "print(inputs[0:10])\n",
    "\n",
    "#shuffle(inputs)\n",
    "#inputs = inputs[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.8444218515250481, 0.7579544029403025, 0.420571580830845, 0.25891675029296335, 0.5112747213686085], [0.4049341374504143, 0.7837985890347726, 0.30331272607892745, 0.4765969541523558, 0.5833820394550312], [0.9081128851953352, 0.5046868558173903, 0.28183784439970383, 0.7558042041572239, 0.6183689966753316], [0.25050634136244054, 0.9097462559682401, 0.9827854760376531, 0.8102172359965896, 0.9021659504395827]], [[0.3101475693193326, 0.7298317482601286, 0.8988382879679935, 0.6839839319154413, 0.47214271545271336], [0.1007012080683658, 0.4341718354537837, 0.6108869734438016, 0.9130110532378982, 0.9666063677707588], [0.47700977655271704, 0.8653099277716401, 0.2604923103919594, 0.8050278270130223, 0.5486993038355893]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3000/3000 [01:30<00:00, 32.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2.5603100507885683, 1.1529064487573306, 3.4897169607266645, 3.2093810513129433, 7.657452006603896], [56.33939127800425, 2.488708266753539, -6.623449443347104, 9.364473788168844, -6.009975096194004], [45.67873940129307, -0.7659575923763904, 11.305505981930416, 6.557174267731038, -27.00770917950639], [1.450482394939248, 0.9430368589386668, 3.833261584236663, 3.1178722525099642, 7.863923239053654]], [[-14.848063151451253, 47.13353627144578, 5.026361411341153, -15.567933952265761, -17.785110087164316], [-0.9574856810900833, -2.4057102111377513, -3.3975668889105983, 0.5790131678886916, 1.6810849994840737], [-1.04321524116235, 1.2705829565263909, -4.073540140330175, -0.651479848006928, -0.4617129695327657]]]\n"
     ]
    }
   ],
   "source": [
    "########### Træning af model ###########\n",
    "\n",
    "###########\n",
    "# Opsætning af Neural Network\n",
    "###########\n",
    "random.seed(0) # to get repeatable results\n",
    "input_size = 4 # antal af input noder (samme antal som feautures)\n",
    "num_hidden = 4 # antal af hidden noder\n",
    "output_size = 3 # antal af output noder (i vores tilfælde, genres)\n",
    "\n",
    "# each hidden neuron has one weight per input, plus a bias weight\n",
    "hidden_layer = [[random.random() for __ in range(input_size + 1)] for __ in range(num_hidden)]\n",
    "\n",
    "# each output neuron has one weight per hidden neuron, plus a bias weight\n",
    "output_layer = [[random.random() for __ in range(num_hidden + 1)] for __ in range(output_size)]\n",
    "\n",
    "# the network starts out with random weights\n",
    "network = [hidden_layer, output_layer]\n",
    "\n",
    "# Iteration of training\n",
    "#num = 0\n",
    "print(network)\n",
    "for __ in  tqdm(range(3000)):\n",
    "    #num = num +1\n",
    "    #if num == 200 or num == 1000 or num == 1500 or num == 2000 or num == 3500:\n",
    "     #   print(network)\n",
    "    for input_vector, target_vector in zip(inputs, targets):\n",
    "        backpropagate(network, input_vector, target_vector)\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      genre                                             lyrics\n",
      "4575   Rock  you have always lived like this the ice blue c...\n",
      "5040   Rock  is their anyone out there earth calling is the...\n",
      "32999   Pop  i've always been the kinda girl that hid my fa...\n",
      "11862   Pop  i wanted to talk to you - pick up the phone i ...\n",
      "12724   Pop  save your point of view for the manic charm th...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing sentiment...: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 742.68it/s]\n",
      "Analyzing sentiment...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<?, ?it/s]\n",
      "Analyzing sentiment...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 100342.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# features\n",
    "test_df = test_df.copy()\n",
    "test_df = test_df.sample(100)\n",
    "print(test_df.tail())\n",
    "test_df = sentence_avg_word_length(test_df,\"avg_word_len\", 'lyrics')\n",
    "test_df = word_count(test_df,\"word_count\", 'lyrics')\n",
    "test_df = normalize(test_df, 'word_count_nm', 'word_count')\n",
    "test_df = analyze_sentiment(test_df)\n",
    "\n",
    "polarity = test_df['polarity']\n",
    "subjectivity = test_df['subjectivity']\n",
    "nouns = df['nouns']\n",
    "adverbs = df['adverbs']\n",
    "verbs = df['verbs']\n",
    "\n",
    "# Create feature list\n",
    "test_features = [[f, p, s, n] for f, p, s, n in zip(test_df[\"word_count_nm\"], polarity, subjectivity, nouns)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################\n",
      "Index(['Hip-Hop', 'Rock', 'Pop'], dtype='object')\n",
      "[1.2240209566865162e-21, 0.7858725398881213, 0.10386113703750448]\n"
     ]
    }
   ],
   "source": [
    "# 'Rock', 'Pop', 'Hip-Hop', 'Not Available', 'Metal', 'Country', 'Jazz', 'Electronic', 'Other', 'R&B', 'Indie', 'Folk'\n",
    "\n",
    "\n",
    "print('##########################')\n",
    "print(genre_labels)\n",
    "res = predict([0.0152699731248473, 0.12666666666666668, 0.4533333333333333,0.10], network)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.975338374365715, 0.01324970870901831, 0.0087380774460874]\n",
      "Hip-Hop\n",
      "[0.9812736909388093, 0.01097972135162718, 0.006968527709036214]\n",
      "Hip-Hop\n",
      "[0.24739986130119335, 0.24955377831298206, 0.291667797013161]\n",
      "[0.5975073350439479, 0.10989811722611213, 0.1119260483719831]\n",
      "[0.25704184068003777, 0.2482716999009484, 0.29077562896102005]\n",
      "Pop\n",
      "[0.9812711499039566, 0.010979849745903098, 0.006968580513997374]\n",
      "Hip-Hop\n",
      "[0.3294239951051432, 0.20681205478822898, 0.23595880882514422]\n",
      "Hip-Hop\n",
      "[6.769376283711332e-12, 0.5387112832029507, 0.17503995900794012]\n",
      "Rock\n",
      "[0.2712830102275121, 0.23926621737998696, 0.27886525664183803]\n",
      "[0.00011561554933262887, 0.33294921728540894, 0.24947574387307447]\n",
      "[0.19449003400363646, 0.2520193642662699, 0.2892267962010165]\n",
      "[0.25963149201702934, 0.24668573866076612, 0.2886940891949235]\n",
      "Pop\n",
      "[0.2517006274259506, 0.24933278290610023, 0.29179168080866835]\n",
      "[2.4323908389817964e-05, 0.35086333711413054, 0.24169648905227897]\n",
      "Rock\n",
      "[0.3577093689370917, 0.19325166312498926, 0.2181317635661987]\n",
      "[0.3091941320505856, 0.2173241037504778, 0.24983021228081154]\n",
      "Hip-Hop\n",
      "[0.9704890705788474, 0.014984086415532732, 0.010133858295167579]\n",
      "Hip-Hop\n",
      "[0.25899377620326863, 0.2465968531490002, 0.28849309232373516]\n",
      "[1.9908842763360576e-12, 0.5542037034670779, 0.170329698341276]\n",
      "[0.16901019261149786, 0.2542190725549557, 0.28905977072743766]\n",
      "Pop\n",
      "[0.01840043837167834, 0.2779585653275444, 0.27602536380189496]\n",
      "Rock\n",
      "[0.0691601028165199, 0.2640665961471562, 0.2834915727170141]\n",
      "[0.97184555341184, 0.014508957290530833, 0.009748014047126463]\n",
      "Hip-Hop\n",
      "[0.0858714506811366, 0.2617566972669787, 0.2847906033227244]\n",
      "[0.6537509997779184, 0.09496769398834604, 0.09395751939143722]\n",
      "[0.9805196776682615, 0.011281194342167447, 0.007199602562156449]\n",
      "Hip-Hop\n",
      "[0.4878879577548123, 0.1428567306992401, 0.15297021087133386]\n",
      "Hip-Hop\n",
      "[0.9812744023793657, 0.010979743738791601, 0.006968555206344702]\n",
      "Hip-Hop\n",
      "[0.25458004311900256, 0.24921725570259998, 0.29191558195139006]\n",
      "[0.13769809782638182, 0.2564988528790612, 0.2876335320330981]\n",
      "[0.24389165507512678, 0.24973929706482895, 0.29156507534328924]\n",
      "[0.20378262387641025, 0.2519212051767151, 0.29022641378269354]\n",
      "[0.010398585828009895, 0.28393851691574923, 0.2729246015152681]\n",
      "Rock\n",
      "[0.9563895477224994, 0.019613308304374768, 0.014018596595319918]\n",
      "Hip-Hop\n",
      "[0.9791458685565879, 0.011816045887450588, 0.0076124445622899]\n",
      "Hip-Hop\n",
      "[0.24888925037939522, 0.24947593265697143, 0.291710028740937]\n",
      "[0.15929289037305078, 0.2548677677151453, 0.28862355333831863]\n",
      "Pop\n",
      "[1.209100527936183e-15, 0.6446174490213428, 0.14391189454804748]\n",
      "Rock\n",
      "[1.0575358875532504e-14, 0.6189156766949893, 0.1512907845983671]\n",
      "Rock\n",
      "[0.2570515479912581, 0.24837435628545187, 0.29093046941926803]\n",
      "Pop\n",
      "[0.16330521530284192, 0.25461203693506396, 0.2888287260597833]\n",
      "[0.7143871868975408, 0.07985738115164084, 0.07629064174665506]\n",
      "Hip-Hop\n",
      "[0.9812712764165086, 0.010979723120327975, 0.006968480306855227]\n",
      "Hip-Hop\n",
      "[0.9812713344629166, 0.010979723067773462, 0.006968481439487061]\n",
      "Hip-Hop\n",
      "[0.2531365759068777, 0.24916019545499038, 0.29168713751576064]\n",
      "[0.23184703861907402, 0.25040346703515015, 0.2912331516772779]\n",
      "[0.19532415940027278, 0.2525015173364092, 0.29003382078498435]\n",
      "[0.9812673204615423, 0.010981964456791615, 0.006970222868662762]\n",
      "Hip-Hop\n",
      "[4.0294149095113307e-13, 0.5742348487850574, 0.16432641568746464]\n",
      "[0.10560661112892412, 0.259505826321741, 0.2860499987630541]\n",
      "[0.12295599274925921, 0.25782248065333824, 0.2869929132747531]\n",
      "Pop\n",
      "[0.27128620388580266, 0.2390771564231085, 0.27858504778298143]\n",
      "[0.2497006308691082, 0.2493943999969973, 0.2916743691771247]\n",
      "Pop\n",
      "[0.38957358399011477, 0.1793188113141294, 0.19991513065784677]\n",
      "Hip-Hop\n",
      "[0.6329055108585978, 0.10039490456201058, 0.10043669349110279]\n",
      "Hip-Hop\n",
      "[0.9496091366804531, 0.02168065438661276, 0.015819215759059594]\n",
      "[0.3340695526349873, 0.20453549242921176, 0.23296401022862412]\n",
      "[0.2264257259785456, 0.25070860199116907, 0.2910789063418033]\n",
      "Pop\n",
      "[0.8961220524444874, 0.036221449029526974, 0.029389590458198094]\n",
      "Hip-Hop\n",
      "[0.9810423408948019, 0.011073890075941348, 0.0070406186069099375]\n",
      "Hip-Hop\n",
      "[0.25313034523977107, 0.24624754666480556, 0.2873769405887885]\n",
      "[0.07146437476568736, 0.26372993819033286, 0.28370288527663196]\n",
      "[0.00447462761341737, 0.29282399738490106, 0.2684002568927221]\n",
      "Rock\n",
      "[0.9766047980286136, 0.01278383959488579, 0.008369533440015798]\n",
      "Hip-Hop\n",
      "[0.9812710471300246, 0.010979827753763405, 0.006968560846261843]\n",
      "Hip-Hop\n",
      "[0.21827640300910645, 0.251140873093348, 0.29079384348506415]\n",
      "[0.408574536291824, 0.17160061598199294, 0.18988122473552885]\n",
      "Hip-Hop\n",
      "[0.9812406219952388, 0.010992178669384622, 0.0069780068493303544]\n",
      "Hip-Hop\n",
      "[0.2655768293471316, 0.24284222109856662, 0.283601920378453]\n",
      "[0.29624636186012454, 0.22435363430056376, 0.25910626237137574]\n",
      "[0.24441037324333267, 0.249712920157025, 0.29158515099704696]\n",
      "Pop\n",
      "[0.25250961954312345, 0.24925707075524703, 0.2917647887974314]\n",
      "Pop\n",
      "[2.352304900055871e-05, 0.3512450460436315, 0.24152828846139843]\n",
      "Rock\n",
      "[0.2531836064304919, 0.24918578988452825, 0.2917267353297001]\n",
      "Pop\n",
      "[0.26132116959627644, 0.2456578704841573, 0.2873370812959425]\n",
      "[0.254845136633161, 0.24851004288361933, 0.29089987893828445]\n",
      "[0.2548214263975009, 0.24906206015536603, 0.2917134960293757]\n",
      "[0.2595170054045306, 0.24674980091425133, 0.28877824926428863]\n",
      "Pop\n",
      "[0.2156868549044097, 0.2512983342975664, 0.2907224913122473]\n",
      "[0.248269655752038, 0.2494474892437182, 0.291602817504259]\n",
      "[0.07124845182611614, 0.2637521708918945, 0.28367332164453285]\n",
      "Pop\n",
      "[0.31389812200538825, 0.21483376535381923, 0.2465428305253697]\n",
      "[9.075854806891742e-08, 0.41825490603337095, 0.21515167105535524]\n",
      "[0.9812698873838681, 0.010980292044206183, 0.0069689156317011775]\n",
      "Hip-Hop\n",
      "[0.004138093312819315, 0.293654869895461, 0.2679840332053183]\n",
      "Rock\n",
      "[0.273134845902339, 0.2381080020882905, 0.2773296310139014]\n",
      "Pop\n",
      "[0.2572999024330278, 0.24821144811997972, 0.29071387045657526]\n",
      "[0.9812738825985542, 0.0109797325142826, 0.006968538792768643]\n",
      "Hip-Hop\n",
      "[0.1718102906688141, 0.25392357316380604, 0.28902730143358235]\n",
      "Pop\n",
      "[0.06937939568484341, 0.26286886644367474, 0.2818829340191061]\n",
      "[0.2562436226732288, 0.2488270828116062, 0.29151806799045105]\n",
      "Pop\n",
      "[0.2569108936267463, 0.2484417060790134, 0.2910133205688214]\n",
      "[0.43036188857588736, 0.16312060207843923, 0.17890543365528153]\n",
      "[6.080097525543943e-05, 0.3402733033762457, 0.2462415707872671]\n",
      "Rock\n",
      "[0.08110464054297664, 0.262284633286348, 0.2843313145894501]\n",
      "[0.00014411466373584066, 0.33045881304349317, 0.25059155125346144]\n",
      "Rock\n",
      "[0.07630975428247752, 0.2630256576258253, 0.2840886174780074]\n",
      "[0.2554724569930368, 0.24875357016333813, 0.2913237103673514]\n",
      "Pop\n",
      "[0.25678201407644957, 0.24827724138986995, 0.2907564613097587]\n",
      "Pop\n",
      "[0.16925134852920837, 0.25418921750373413, 0.289056684893401]\n",
      "Pop\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for test, t in zip(test_features, test_df['genre']):\n",
    "    test_res = predict(test,network)\n",
    "    print(test_res)\n",
    "    maxnum = test_res.index(max(test_res))\n",
    "    if genre_labels[maxnum] == t:\n",
    "        count = count +1\n",
    "        print(t)\n",
    "        \n",
    "print(count)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
